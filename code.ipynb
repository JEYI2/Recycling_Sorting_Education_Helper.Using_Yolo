{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib>=3.2.2 (from -r yolov7\\requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.9.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy<1.24.0,>=1.18.5 (from -r yolov7\\requirements.txt (line 5))\n",
      "  Downloading numpy-1.23.5-cp311-cp311-win_amd64.whl.metadata (2.3 kB)\n",
      "Collecting opencv-python>=4.1.1 (from -r yolov7\\requirements.txt (line 6))\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 7)) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 8)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 9)) (2.32.3)\n",
      "Collecting scipy>=1.4.1 (from -r yolov7\\requirements.txt (line 10))\n",
      "  Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 11)) (2.5.1)\n",
      "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 12)) (0.20.1)\n",
      "Collecting tqdm>=4.41.0 (from -r yolov7\\requirements.txt (line 13))\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting protobuf<4.21.3 (from -r yolov7\\requirements.txt (line 14))\n",
      "  Downloading protobuf-4.21.2-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Collecting tensorboard>=2.4.1 (from -r yolov7\\requirements.txt (line 17))\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pandas>=1.1.4 (from -r yolov7\\requirements.txt (line 21))\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting seaborn>=0.11.0 (from -r yolov7\\requirements.txt (line 22))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 34)) (8.29.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from -r yolov7\\requirements.txt (line 35)) (5.9.0)\n",
      "Collecting thop (from -r yolov7\\requirements.txt (line 36))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4))\n",
      "  Downloading contourpy-1.3.0-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4))\n",
      "  Downloading fonttools-4.54.1-cp311-cp311-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4))\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4)) (24.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4))\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from matplotlib>=3.2.2->-r yolov7\\requirements.txt (line 4)) (2.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.23.0->-r yolov7\\requirements.txt (line 9)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.23.0->-r yolov7\\requirements.txt (line 9)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.23.0->-r yolov7\\requirements.txt (line 9)) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from requests>=2.23.0->-r yolov7\\requirements.txt (line 9)) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11)) (4.11.0)\n",
      "Collecting sympy==1.13.1 (from torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11))\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11)) (3.1.4)\n",
      "Collecting fsspec (from torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11))\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from sympy==1.13.1->torch!=1.12.0,>=1.7.0->-r yolov7\\requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from tqdm>=4.41.0->-r yolov7\\requirements.txt (line 13)) (0.4.6)\n",
      "Collecting absl-py>=0.4 (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17))\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17))\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17))\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17)) (75.1.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17)) (1.16.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17))\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.4->-r yolov7\\requirements.txt (line 21))\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.4->-r yolov7\\requirements.txt (line 21))\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from ipython->-r yolov7\\requirements.txt (line 34)) (5.14.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from jedi>=0.16->ipython->-r yolov7\\requirements.txt (line 34)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->-r yolov7\\requirements.txt (line 34)) (0.2.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r yolov7\\requirements.txt (line 17)) (2.1.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from stack-data->ipython->-r yolov7\\requirements.txt (line 34)) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from stack-data->ipython->-r yolov7\\requirements.txt (line 34)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\daftg\\anaconda3\\envs\\deeplearning\\lib\\site-packages (from stack-data->ipython->-r yolov7\\requirements.txt (line 34)) (0.2.3)\n",
      "Downloading matplotlib-3.9.2-cp311-cp311-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 5.2/7.8 MB 26.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading numpy-1.23.5-cp311-cp311-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 7.6/14.6 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 35.4 MB/s eta 0:00:00\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "   ---------------------------------------- 0.0/38.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.7/38.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 11.3/38.8 MB 30.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 18.9/38.8 MB 32.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 26.2/38.8 MB 33.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/38.8 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.8/38.8 MB 32.5 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp311-cp311-win_amd64.whl (44.8 MB)\n",
      "   ---------------------------------------- 0.0/44.8 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 7.3/44.8 MB 37.6 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 15.2/44.8 MB 36.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 21.0/44.8 MB 35.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 21.8/44.8 MB 26.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 29.4/44.8 MB 27.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.0/44.8 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.6/44.8 MB 30.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.8/44.8 MB 29.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 34.5 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Downloading protobuf-4.21.2-cp310-abi3-win_amd64.whl (524 kB)\n",
      "   ---------------------------------------- 0.0/525.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 525.0/525.0 kB 16.4 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 33.4 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 7.6/11.6 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 34.6 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading contourpy-1.3.0-cp311-cp311-win_amd64.whl (217 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 30.9 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.67.1-cp311-cp311-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 3.1/4.4 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.4/4.4 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp311-cp311-win_amd64.whl (56 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: pytz, werkzeug, tzdata, tqdm, tensorboard-data-server, sympy, pyparsing, protobuf, numpy, markdown, kiwisolver, grpcio, fsspec, fonttools, cycler, absl-py, tensorboard, scipy, pandas, opencv-python, contourpy, thop, matplotlib, seaborn\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.2\n",
      "    Uninstalling sympy-1.13.2:\n",
      "      Successfully uninstalled sympy-1.13.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed absl-py-2.1.0 contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 fsspec-2024.10.0 grpcio-1.67.1 kiwisolver-1.4.7 markdown-3.7 matplotlib-3.9.2 numpy-1.23.5 opencv-python-4.10.0.84 pandas-2.2.3 protobuf-4.21.2 pyparsing-3.2.0 pytz-2024.2 scipy-1.14.1 seaborn-0.13.2 sympy-1.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 thop-0.1.1.post2209072238 tqdm-4.66.6 tzdata-2024.2 werkzeug-3.0.6\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r yolov7\\requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지가 성공적으로 분리되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 이미지가 저장된 폴더 경로\n",
    "image_folder = 'E:/1.files/deeplearning/new_images/images'\n",
    "# 이미지를 옮길 폴더 경로 (이미 만들어 놓은 폴더)\n",
    "train_folder = 'E:/1.files/deeplearning/yolov7/data/train/images'\n",
    "validation_folder = 'E:/1.files/deeplearning/yolov7/data/val/images'\n",
    "test_folder = 'E:/1.files/deeplearning/yolov7/data/test/images'\n",
    "\n",
    "# 이미지 파일 리스트 가져오기\n",
    "images = os.listdir(image_folder)\n",
    "images.sort()  # 정렬하여 일관성 있는 선택을 위해\n",
    "\n",
    "# 각 데이터셋에 대한 리스트 초기화\n",
    "train_images = []\n",
    "validation_images = []\n",
    "test_images = []\n",
    "\n",
    "# 간격을 두고 선택\n",
    "for i in range(len(images)):\n",
    "    if i % 10 < 8:  # 0~7번째 인덱스는 train\n",
    "        train_images.append(images[i])\n",
    "    elif i % 10 == 8:  # 8번째 인덱스는 validation\n",
    "        validation_images.append(images[i])\n",
    "    else:  # 9번째 인덱스는 test\n",
    "        test_images.append(images[i])\n",
    "\n",
    "# 이미지 이동\n",
    "for img in train_images:\n",
    "    shutil.copy(os.path.join(image_folder, img), os.path.join(train_folder, img))\n",
    "for img in validation_images:\n",
    "    shutil.copy(os.path.join(image_folder, img), os.path.join(validation_folder, img))\n",
    "for img in test_images:\n",
    "    shutil.copy(os.path.join(image_folder, img), os.path.join(test_folder, img))\n",
    "\n",
    "print(\"이미지가 성공적으로 분리되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 정의에 따라 label_set들을 class를 0부터 시작하는 정수 번호로 지정해주는 함수를 정의한다.\n",
    "def class_choose(cls):\n",
    "    paper = ['c_1','c_2_01','c_2_02', 'c_1_01', 'c_2_02_01']\n",
    "    glass = ['c_4_01_02','c_4_02_01_02','c_4_02_02_02','c_4_02_03_02','c_4_03', 'c_4_03_01', 'c_4_01_01', 'c_4_02_01_01', 'c_4_02_02_01', 'c_4_02_03_01']\n",
    "    pet = ['c_5_02', 'c_5_01_01', 'c_5_02_01', 'c_5_01']\n",
    "    plastic =['c_6', 'c_6_01']\n",
    "    can = ['c_3', 'c_3_01']\n",
    "    vinyl =['c_7', 'c_7_01']\n",
    "    battery =['c_9']\n",
    "    styro=['c_8_01','c_8_02', 'c_8_01_01']\n",
    "\n",
    "    if cls in paper:\n",
    "        return 0\n",
    "    elif cls in glass:\n",
    "        return 1\n",
    "    elif cls in pet:\n",
    "        return 2\n",
    "    elif cls in plastic:\n",
    "        return 3\n",
    "    elif cls in can:\n",
    "        return 4\n",
    "    elif cls in vinyl:\n",
    "        return 5\n",
    "    elif cls in battery:\n",
    "        return 6\n",
    "    elif cls in styro:\n",
    "        return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def resize_and_label(image_dir, output_label_dir):\n",
    "    # 통일할 이미지 크기 설정 (예: 1280x1280)\n",
    "    target_size = (640, 640)\n",
    "\n",
    "    # 이미지 및 레이블 디렉토리 경로 설정\n",
    "    label_dir = 'E:/1.files/deeplearning/new_images/labels'  # JSON 레이블 디렉토리\n",
    "\n",
    "    # 이미지 파일 이름 목록 생성\n",
    "    names = [os.path.splitext(file)[0] for file in os.listdir(image_dir) if file.lower().endswith('.jpg')]\n",
    "    print(len(names))\n",
    "\n",
    "    for file in tqdm(names, desc=\"처리 진행 상황\"):\n",
    "        json_path = os.path.join(label_dir, file + '.json')\n",
    "        img_path = os.path.join(image_dir, file + '.jpg')\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:  # 이미지가 제대로 읽히지 않은 경우\n",
    "            print(f\"이미지를 읽을 수 없습니다: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        # 원본 이미지 크기 가져오기\n",
    "        h, w, _ = image.shape\n",
    "\n",
    "        # 이미지 크기 조정\n",
    "        resized_image = cv2.resize(image, target_size)\n",
    "        resized_h, resized_w = target_size  # 조정된 이미지 크기\n",
    "\n",
    "        # JSON 파일 열기\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            json_data = json.load(f)\n",
    "\n",
    "        objs = []\n",
    "        for obj in json_data['objects']:\n",
    "            if obj['annotation_type'] != 'box':  # bbox가 아닌 polygon 등 제외\n",
    "                continue\n",
    "            cls = obj['class_name']\n",
    "            cls_num = class_choose(cls)  # 클래스 숫자로 변환하는 함수 (직접 구현 필요)\n",
    "\n",
    "            # JSON 파일에서 x, y, width, height 값 가져오기\n",
    "            x = obj['annotation']['coord']['x']\n",
    "            y = obj['annotation']['coord']['y']\n",
    "            width = obj['annotation']['coord']['width']\n",
    "            height = obj['annotation']['coord']['height']\n",
    "\n",
    "            # 좌표 변환 비율 계산\n",
    "            width_ratio = target_size[0] / w\n",
    "            height_ratio = target_size[1] / h\n",
    "\n",
    "            # 좌표를 변환된 이미지 크기에 맞게 조정\n",
    "            x1 = x * width_ratio\n",
    "            y1 = y * height_ratio\n",
    "            x2 = (x + width) * width_ratio\n",
    "            y2 = (y + height) * height_ratio\n",
    "\n",
    "            # YOLO 포맷으로 변환\n",
    "            center_x = (x1 + x2) / (2 * resized_w)\n",
    "            center_y = (y1 + y2) / (2 * resized_h)\n",
    "            width_norm = (x2 - x1) / resized_w\n",
    "            height_norm = (y2 - y1) / resized_h\n",
    "\n",
    "            objs.append(f'{cls_num} {center_x} {center_y} {width_norm} {height_norm}\\n')\n",
    "\n",
    "        # YOLO 형식의 라벨 파일 저장\n",
    "        output_path = os.path.join(output_label_dir, f'{file}.txt')\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.writelines(objs)\n",
    "\n",
    "        # 조정된 이미지 저장 (원하는 경우)\n",
    "        output_image_path = os.path.join(image_dir, f'{file}.jpg')  # 원래 경로에 저장하려면 주석 해제\n",
    "        cv2.imwrite(output_image_path, resized_image)\n",
    "\n",
    "    print(\"변환이 완료되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두 폴더의 파일 이름이 동일합니다.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def compare_folders(a_folder, b_folder):\n",
    "    \"\"\"\n",
    "    두 폴더(a_folder, b_folder) 내의 파일 이름(확장자 제외)이 동일한지 확인하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "    - a_folder: 첫 번째 폴더 경로.\n",
    "    - b_folder: 두 번째 폴더 경로.\n",
    "    \n",
    "    Returns:\n",
    "    - 동일한 파일 이름이 있는지 여부를 반환.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 각 폴더의 파일 목록 가져오기 (확장자 제외한 파일 이름만)\n",
    "    a_files = {os.path.splitext(f)[0] for f in os.listdir(a_folder)}\n",
    "    b_files = {os.path.splitext(f)[0] for f in os.listdir(b_folder)}\n",
    "    \n",
    "    # 두 폴더의 파일 이름 비교\n",
    "    if a_files == b_files:\n",
    "        print(\"두 폴더의 파일 이름이 동일합니다.\")\n",
    "        return True\n",
    "    else:\n",
    "        # 파일 이름 차이점 출력\n",
    "        only_in_a = a_files - b_files\n",
    "        only_in_b = b_files - a_files\n",
    "        \n",
    "        if only_in_a:\n",
    "            print(f\"a 폴더에만 있는 파일들: {only_in_a}\")\n",
    "        if only_in_b:\n",
    "            print(f\"b 폴더에만 있는 파일들: {only_in_b}\")\n",
    "        \n",
    "        return False\n",
    "\n",
    "# 사용 예시\n",
    "a_folder = \"E:/1.files/deeplearning/new_images/images\"\n",
    "b_folder = \"E:/1.files/deeplearning/new_images/labels\"\n",
    "\n",
    "compare_folders(a_folder, b_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "처리 진행 상황: 100%|██████████| 363/363 [00:31<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환이 완료되었습니다.\n",
      "2908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "처리 진행 상황: 100%|██████████| 2908/2908 [05:42<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환이 완료되었습니다.\n",
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "처리 진행 상황: 100%|██████████| 363/363 [00:43<00:00,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환이 완료되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'E:/1.files/deeplearning/yolov7/data/test/images'  # 이미지 디렉토리\n",
    "output_label_dir = 'E:/1.files/deeplearning/yolov7/data/test/labels' # YOLO 형식으로 변환한 레이블 저장 경로\n",
    "resize_and_label(image_dir, output_label_dir)\n",
    "\n",
    "image_dir = 'E:/1.files/deeplearning/yolov7/data/train/images'  # 이미지 디렉토리\n",
    "output_label_dir = 'E:/1.files/deeplearning/yolov7/data/train/labels' # YOLO 형식으로 변환한 레이블 저장 경로\n",
    "resize_and_label(image_dir, output_label_dir)\n",
    "\n",
    "image_dir = 'E:/1.files/deeplearning/yolov7/data/val/images'  # 이미지 디렉토리\n",
    "output_label_dir = 'E:/1.files/deeplearning/yolov7/data/val/labels' # YOLO 형식으로 변환한 레이블 저장 경로\n",
    "resize_and_label(image_dir, output_label_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 896 objects\n",
      "Class 4: 983 objects\n",
      "Class 2: 817 objects\n",
      "Class 3: 1122 objects\n",
      "Class 5: 938 objects\n",
      "Class 0: 1336 objects\n",
      "Class 6: 782 objects\n",
      "Class 7: 813 objects\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_objects_by_class(label_folder):\n",
    "    \"\"\"\n",
    "    모든 라벨 파일을 순회하며 클래스별 객체 개수를 세는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "    - label_folder: 라벨 파일이 저장된 경로.\n",
    "    \n",
    "    Returns:\n",
    "    - class_counts: 클래스 ID를 키로 하고, 각 클래스별 객체 수를 값으로 가지는 딕셔너리.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 클래스별 객체 수를 저장할 딕셔너리 초기화\n",
    "    class_counts = defaultdict(int)\n",
    "    \n",
    "    # 라벨 폴더 내 모든 파일을 순회\n",
    "    for label_file in os.listdir(label_folder):\n",
    "        label_path = os.path.join(label_folder, label_file)\n",
    "        \n",
    "        # 라벨 파일 읽기\n",
    "        with open(label_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            \n",
    "            for line in lines:\n",
    "                # 객체 정보를 YOLO 형식으로 파싱\n",
    "                parts = line.strip().split()\n",
    "                class_id = int(parts[0])\n",
    "                \n",
    "                # 해당 클래스 ID의 객체 수 증가\n",
    "                class_counts[class_id] += 1\n",
    "    \n",
    "    return class_counts\n",
    "\n",
    "# 사용 예시\n",
    "label_folder = \"path/to/labels\"\n",
    "class_counts = count_objects_by_class('E:/1.files/deeplearning/yolov7/data/train/labels')\n",
    "\n",
    "# 클래스별 객체 개수 출력\n",
    "for class_id, count in class_counts.items():\n",
    "    print(f\"Class {class_id}: {count} objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비어있는 라벨 파일이 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_empty_labels(label_folder):\n",
    "    \"\"\"\n",
    "    주어진 폴더 내의 YOLO 라벨 텍스트 파일들이 비어있는지 확인하고 출력합니다.\n",
    "\n",
    "    Parameters:\n",
    "    - label_folder: 라벨 파일들이 들어 있는 폴더 경로.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 라벨 파일들이 들어 있는 폴더 내의 모든 파일을 확인\n",
    "    empty_files = []  # 비어있는 파일 목록\n",
    "    \n",
    "    for filename in os.listdir(label_folder):\n",
    "        # 텍스트 파일만 필터링\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(label_folder, filename)\n",
    "            \n",
    "            # 파일이 비어있는지 확인\n",
    "            if os.path.getsize(file_path) == 0:\n",
    "                empty_files.append(filename)\n",
    "    \n",
    "    # 결과 출력\n",
    "    if empty_files:\n",
    "        print(f\"비어있는 라벨 파일들: {empty_files}\")\n",
    "    else:\n",
    "        print(\"비어있는 라벨 파일이 없습니다.\")\n",
    "\n",
    "# 사용 예시\n",
    "label_folder = \"yolov7/data/val/labels\"\n",
    "check_empty_labels(label_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 라벨 파일이 유효합니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def check_invalid_coordinates(label_folder):\n",
    "    \"\"\"\n",
    "    주어진 폴더 내의 YOLO 라벨 파일들이 유효한지 확인하고 잘못된 좌표값을 찾습니다.\n",
    "\n",
    "    Parameters:\n",
    "    - label_folder: 라벨 파일들이 들어 있는 폴더 경로.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 라벨 파일들이 들어 있는 폴더 내의 모든 파일을 확인\n",
    "    invalid_files = []  # 잘못된 좌표값을 가진 파일 목록\n",
    "    \n",
    "    for filename in os.listdir(label_folder):\n",
    "        # 텍스트 파일만 필터링\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(label_folder, filename)\n",
    "            \n",
    "            with open(file_path, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "                \n",
    "                for line in lines:\n",
    "                    # 각 라벨 줄을 공백 기준으로 나눔\n",
    "                    values = line.strip().split()\n",
    "                    \n",
    "                    # 값이 5개인지 확인 (class x_center y_center width height)\n",
    "                    if len(values) == 5:\n",
    "                        try:\n",
    "                            # 각 값 파싱\n",
    "                            cls, x_center, y_center, width, height = map(float, values)\n",
    "                            \n",
    "                            # 클래스 값 확인 (양의 정수)\n",
    "                            if cls < 0 or not cls.is_integer():\n",
    "                                invalid_files.append(f\"{filename} (Invalid class: {cls})\")\n",
    "                            \n",
    "                            # 좌표 값 확인 (0 ~ 1 사이의 값이어야 함)\n",
    "                            if not (0 <= x_center <= 1 and 0 <= y_center <= 1 and 0 <= width <= 1 and 0 <= height <= 1):\n",
    "                                invalid_files.append(f\"{filename} (Invalid coordinates: {values})\")\n",
    "                            \n",
    "                        except ValueError:\n",
    "                            # 값이 실수로 변환되지 않으면 잘못된 라벨로 처리\n",
    "                            invalid_files.append(f\"{filename} (Invalid value format)\")\n",
    "    \n",
    "    # 결과 출력\n",
    "    if invalid_files:\n",
    "        print(\"잘못된 좌표값을 가진 파일들:\")\n",
    "        for file in invalid_files:\n",
    "            print(file)\n",
    "    else:\n",
    "        print(\"모든 라벨 파일이 유효합니다.\")\n",
    "\n",
    "# 사용 예시\n",
    "label_folder = \"yolov7/data/test/labels\"\n",
    "check_invalid_coordinates(label_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
